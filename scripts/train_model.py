import pandas as pd
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np
import joblib
from google.cloud import storage
import io

# Function to load data from Google Cloud Storage
def load_data_from_gcs(bucket_name, file_path):
    client = storage.Client()
    bucket = client.get_bucket(bucket_name)
    blob = bucket.blob(file_path)
    data = blob.download_as_string()
    return pd.read_csv(io.StringIO(data.decode('utf-8')))

# Function to save model to GCS
def save_model_to_gcs(model, bucket_name, file_path):
    client = storage.Client()
    bucket = client.get_bucket(bucket_name)
    blob = bucket.blob(file_path)
    # Serialize the model and upload to GCS
    model_data = io.BytesIO()
    joblib.dump(model, model_data)
    model_data.seek(0)
    blob.upload_from_file(model_data, content_type='application/octet-stream')

# Step 1: Prepare Data
def prepare_data(df):
    df['datetime'] = pd.to_datetime(df['datetime'])

    # Create 'season' feature
    df['season'] = df['datetime'].dt.month % 12 // 3 + 1
    df['day_of_year'] = df['datetime'].dt.dayofyear

    # Additional Time-based features
    df['day_of_week'] = df['datetime'].dt.dayofweek
    df['month'] = df['datetime'].dt.month
    df['is_weekend'] = df['day_of_week'].apply(lambda x: 1 if x >= 5 else 0)

    # Remove or reduce lag features for simplicity
    df['AQI_lag_1'] = df['AQI Value'].shift(1)
    df['AQI_lag_3'] = df['AQI Value'].shift(3)

    # Rolling averages
    df['temp_mean_7d_avg'] = df['temp_mean'].rolling(window=7).mean()
    df['humidity_mean_7d_avg'] = df['humidity_mean'].rolling(window=7).mean()

    # Polynomial features
    df['temp_mean_squared'] = df['temp_mean'] ** 2

    # Ensure numeric data types, replace non-numeric values like '.' with NaN
    df = df.apply(pd.to_numeric, errors='coerce')

    # Drop NaNs generated by rolling, lag features, and non-numeric replacements
    df = df.dropna(subset=['AQI Value', 'temp_mean_7d_avg', 'AQI_lag_1'])

    # Select relevant features (simplified)
    features = [
        'temp_mean', 'temp_max_mean', 'temp_min_mean', 'wind_speed_mean', 'humidity_mean',
        'pressure_mean', 'clouds_all_mean', 'season', 'day_of_year', 'day_of_week', 'is_weekend',
        'AQI_lag_1', 'AQI_lag_3', 'temp_mean_7d_avg', 'humidity_mean_7d_avg', 'temp_mean_squared'
    ]

    X = df[features]
    y = df['AQI Value']

    # Return the unscaled data for tree-based models
    return X, y


# Step 2: Split Data
def split_data(X, y):
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    return X_train, X_test, y_train, y_test


# Step 3: Train Model with Hyperparameter Tuning using RandomizedSearchCV
def train_random_forest_with_tuning(X_train, y_train):
    param_grid = {
        'n_estimators': [100, 500, 1000],
        'max_depth': [None, 10, 20],
        'min_samples_split': [2, 5, 10],
        'min_samples_leaf': [1, 2, 4],
        'max_features': ['sqrt', 'log2', None]
    }

    rf = RandomForestRegressor(random_state=42)
    rf_random = RandomizedSearchCV(estimator=rf, param_distributions=param_grid,
                                   n_iter=20, cv=5, verbose=2, random_state=42, n_jobs=-1)

    rf_random.fit(X_train, y_train)

    print("Best parameters found:", rf_random.best_params_)
    return rf_random.best_estimator_


# Step 4: Evaluate Model
def evaluate_model(model, X_test, y_test):
    y_pred = model.predict(X_test)
    mae = mean_absolute_error(y_test, y_pred)
    mse = mean_squared_error(y_test, y_pred)
    rmse = mse ** 0.5
    r2 = r2_score(y_test, y_pred)

    print(f"MAE: {mae}")
    print(f"RMSE: {rmse}")
    print(f"RÂ² Score: {r2}")


if __name__ == "__main__":
    bucket_name = 'weather-aqi-data-storage'
    data_path = 'merged_weather_aqi_2014_2024.csv'
    model_save_path = 'models/trained_model.pkl'

    # Load data from GCS
    df = load_data_from_gcs(bucket_name, data_path)

    # Prepare and split data
    X, y = prepare_data(df)
    X_train, X_test, y_train, y_test = split_data(X, y)

    # Train Random Forest (using unscaled data)
    print("Training Random Forest model with hyperparameter tuning...")
    best_rf_model = train_random_forest_with_tuning(X_train, y_train)
    print("Best Random Forest Model training completed.")

    # Evaluate Random Forest Model
    evaluate_model(best_rf_model, X_test, y_test)

    # Save the trained model to GCS
    save_model_to_gcs(best_rf_model, bucket_name, model_save_path)
    print(f"Model saved successfully to 'gs://{bucket_name}/{model_save_path}'.")